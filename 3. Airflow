from pyspark.sql import SparkSession
from pyspark.sql.functions import col, sum

# SparkSession
spark = SparkSession.builder.getOrCreate()

# Replace with your source details (e.g., reading from cloud storage)
df = spark.read.format("source_format").option("path", "source_path").load()

# Data transformation (replace with your logic)
transformed_df = df.groupBy("category").agg(sum("amount").alias("total_amount"))

# Write transformed data to Snowflake stage 
transformed_df.write.format("snowflake").option("url", "your_snowflake_url")\
  .option("user", "your_username").option("password", "your_password")\
  .option("db", "your_database").option("schema", "your_schema")\
  .option("table", "daily_processed_data").mode("append").save()

# Stop SparkSession
spark.stop()
